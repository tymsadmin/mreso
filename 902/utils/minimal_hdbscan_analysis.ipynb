{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNajypgZuq8C8GKgPCfpr0F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EADmt2pu3My2","executionInfo":{"status":"ok","timestamp":1734816980528,"user_tz":-60,"elapsed":2099,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}},"outputId":"0dec922f-d7b9-42af-9ea1-8532c26e1d00"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install hdbscan"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LDSVlHR4PSX","executionInfo":{"status":"ok","timestamp":1734816990476,"user_tz":-60,"elapsed":9949,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}},"outputId":"21b8d79e-1e93-4b2c-b301-2579d765c6fd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: hdbscan in /usr/local/lib/python3.10/dist-packages (0.8.40)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.26.4)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.6.0)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->hdbscan) (3.5.0)\n"]}]},{"cell_type":"code","source":["###############################################################################\n","# NOTE : L'algorithme va ajouter une colonne 'cluster_label' dans le DataFrame\n","#        et donc dans le CSV final. Les valeurs correspondront aux numéros\n","#        de cluster identifiés. Si l'étiquette vaut -1, alors le point sera\n","#        considéré comme du « bruit » (noise) et n'appartiendra à aucun cluster.\n","###############################################################################"],"metadata":{"id":"n0QZWaHnF8Yf","executionInfo":{"status":"ok","timestamp":1734816990476,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"xuVwVq1PyR3_","executionInfo":{"status":"ok","timestamp":1734816990476,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}},"outputId":"5d7c0361-4173-4374-e183-4248e61fb65c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nMéthode de sélection finale des clusters.\\n'leaf' = on découpe la hiérarchie jusqu’aux feuilles stables\\n'eom' = on fait un trade off en remontant la hiérarchie pour fusionner certaines feuilles \\n        jugées insuffisamment stables individuellement.\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["###############################################################################\n","#                          BLOC DE CONFIGURATION                              #\n","###############################################################################\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","# Bibliothèque HDBSCAN\n","# !pip install hdbscan\n","import hdbscan\n","\n","from typing import List\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","###############################################################################\n","# Paramètres de chargement de données\n","###############################################################################\n","\n","# Chemin du dossier dans lequel se trouve le CSV\n","folder_path = \"/content/drive/MyDrive/COLAB_NLP/DATA/\"\n","\n","# Nom du fichier CSV à traiter\n","csv_file = \"transcripts.csv\"\n","\n","# Séparateur par défaut (utilisé en fallback) : ',' ou ';'\n","# La détection automatique ajustera cette valeur.\n","default_sep = \",\"\n","\n","\n","###############################################################################\n","# Paramètres de clustering\n","###############################################################################\n","\n","# Colonnes à utiliser pour le clustering (elles doivent être numériques !)\n","columns_to_use = [\"video_view_count\", \"video_like_count\", \"video_comment_count\", \"sentiment\"]\n","\n","# Taille minimale d'un cluster.\n","# Il est crucial de définir une valeur élevée pour `min_cluster_size` (par exemple, 1000)\n","# afin d'éviter la formation de micro-clusters difficiles, voire impossibles, à interpréter.\n","# Une valeur élevée garantit que les clusters sont plus larges, plus \"stables\", et reste dans un\n","# scope raisonnable pour une analyse humaine (idéalement, entre 10/15 clusters maximum).\n","# Si vous diminuez cette valeur, vous autorisez la formation de clusters plus petits,\n","# qui peuvent révéler des sous-groupes fins, mais risquent de manquer de signification\n","# ou de complexifier inutilement l'interprétation.\n","min_cluster_size = 1000\n","\n","# Méthode de sélection finale des clusters.\n","# - 'leaf' : on découpe la hiérarchie jusqu’aux feuilles stables.\n","# - 'eom' : on fait un trade-off en remontant la hiérarchie pour fusionner certaines feuilles\n","#           jugées insuffisamment stables individuellement.\n","cluster_selection_method = 'eom'"]},{"cell_type":"code","source":["def detect_separator(csv_file_path: str) -> str:\n","    \"\"\"\n","    Détecte s’il y a plus de virgules ou de points-virgules dans la première ligne\n","    du fichier pour faire un guess sur le délimiteur (',' ou ';').\n","    \"\"\"\n","    with open(csv_file_path, 'r', encoding='utf-8') as f:\n","        first_line = f.readline()\n","    nb_commas = first_line.count(',')\n","    nb_semicolons = first_line.count(';')\n","    return ';' if nb_semicolons > nb_commas else ','"],"metadata":{"id":"sQSR96ZvyTlb","executionInfo":{"status":"ok","timestamp":1734816990476,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def load_data(csv_file_path: str, user_default_sep: str = ',') -> pd.DataFrame:\n","    \"\"\"\n","    1. Détecte le séparateur via detect_separator().\n","    2. Charge les données avec pandas, en se basant sur le séparateur détecté.\n","    \"\"\"\n","    sep_found = detect_separator(csv_file_path)\n","    print(f\"[*] Séparateur détecté : '{sep_found}' (défaut : '{user_default_sep}')\")\n","\n","    df = pd.read_csv(csv_file_path, sep=sep_found, encoding='utf-8')\n","    print(f\"[*] CSV chargé : {df.shape[0]} lignes, {df.shape[1]} colonnes.\")\n","    return df"],"metadata":{"id":"L2XMqDy4yTi1","executionInfo":{"status":"ok","timestamp":1734816990476,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def apply_hdbscan(df: pd.DataFrame,\n","                  features: List[str],\n","                  min_cluster_size: int = 5,\n","                  cluster_selection_method: str = 'eom'\n","                  ) -> np.ndarray:\n","    \"\"\"\n","    Applique l'algorithme de clustering HDBSCAN sur les colonnes spécifiées (features).\n","    Retourne un tableau numpy des labels de cluster pour chaque ligne du DataFrame.\n","\n","    Paramètres :\n","      - df : DataFrame initial\n","      - features : liste de colonnes numériques à utiliser pour le clustering\n","      - min_cluster_size : taille minimale d'un cluster\n","      - cluster_selection_method : méthode de sélection de clusters ('eom' ou 'leaf')\n","\n","    Retour :\n","      - cluster_labels : un array contenant le numéro de cluster pour chaque point\n","                         (ou -1 si le point est considéré comme du bruit).\n","    \"\"\"\n","\n","    # Vérification de l'existence des colonnes\n","    for col in features:\n","        if col not in df.columns:\n","            raise ValueError(f\"La colonne '{col}' est introuvable dans le DataFrame.\")\n","\n","    # Extraire les données numériques\n","    data_for_clustering = df[features].values\n","\n","    # --------------------------------------------------------------------------\n","    # Application du MinMaxScaler pour ramener chaque feature dans [0, 1].\n","    # Cela évite qu'une colonne à grande échelle ne domine le calcul des distances.\n","    # --------------------------------------------------------------------------\n","    scaler = MinMaxScaler()\n","    data_for_clustering_scaled = scaler.fit_transform(data_for_clustering)\n","\n","    # Initialiser le clusterer HDBSCAN\n","    clusterer = hdbscan.HDBSCAN(\n","        min_cluster_size=min_cluster_size,\n","        min_samples=None,\n","        metric='euclidean',\n","        cluster_selection_method=cluster_selection_method\n","    )\n","\n","    # Ajuster sur les données (maintenant mises à l'échelle)\n","    print(\"[*] Démarrage du clustering HDBSCAN...\")\n","    clusterer.fit(data_for_clustering_scaled)\n","    print(\"[*] Clustering HDBSCAN terminé.\")\n","\n","    # clusterer.labels_ : tableau contenant le label du cluster de chaque point\n","    cluster_labels = clusterer.labels_\n","\n","    return cluster_labels"],"metadata":{"id":"MvqXFjEOyTgQ","executionInfo":{"status":"ok","timestamp":1734816990476,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def save_clusters_to_csv(df: pd.DataFrame,\n","                         cluster_labels: np.ndarray,\n","                         features: list,\n","                         overwrite: bool = False,\n","                         output_path: str = \"hdbscan_output.csv\",\n","                         sep: str = ','):\n","    \"\"\"\n","    1. Crée un nom de colonne qui inclut tous les noms de variables utilisées,\n","       séparés par '_'.\n","    2. Ajoute les labels de cluster au DataFrame.\n","    3. Sauvegarde le DataFrame mis à jour au format CSV.\n","\n","    - df             : DataFrame initial\n","    - cluster_labels : array des labels de cluster (même longueur que df)\n","    - features       : liste de colonnes utilisées\n","    - overwrite      : True si on veut écraser le CSV d'origine, False sinon\n","    - output_path    : chemin du CSV de sortie\n","    - sep            : séparateur CSV\n","    \"\"\"\n","\n","    # Créer la colonne de cluster, par ex. \"cluster_var1_var2_var3\"\n","    cluster_col_name = \"cluster_\" + \"_\".join(features)\n","\n","    # Ajouter au DataFrame\n","    df[cluster_col_name] = cluster_labels\n","\n","    # Export CSV\n","    df.to_csv(output_path, index=False, sep=sep, encoding='utf-8')\n","    print(f\"[*] Fichier CSV enregistré dans : {output_path}\")\n","    print(f\"    -> Nouvelle colonne : {cluster_col_name}\")"],"metadata":{"id":"uYZYLHBHyTdq","executionInfo":{"status":"ok","timestamp":1734816990476,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def main():\n","    # 1) Construit le chemin complet vers le CSV\n","    full_csv_path = os.path.join(folder_path, csv_file)\n","\n","    # 2) Charge le CSV\n","    df = load_data(full_csv_path, user_default_sep=default_sep)\n","\n","    # 3) Applique HDBSCAN sur les features sélectionnées\n","    cluster_labels = apply_hdbscan(\n","        df,\n","        features=columns_to_use,\n","        min_cluster_size=min_cluster_size,\n","        cluster_selection_method=cluster_selection_method\n","    )\n","\n","    # 5) Sauvegarde le résultat dans un CSV\n","    #    On réutilise le même séparateur détecté au chargement ?\n","    #    Pour cela, on redétecte ou on se fie à default_sep\n","    #    (selon vos préférences, vous pouvez aussi enregistrer avec un nouveau séparateur).\n","    real_sep = detect_separator(full_csv_path)\n","    save_clusters_to_csv(\n","        df=df,\n","        cluster_labels=cluster_labels,\n","        features=columns_to_use,\n","        overwrite=True,\n","        output_path=full_csv_path,\n","        sep=real_sep\n","    )\n","\n","    print(\"[*] Script HDBSCAN terminé avec succès.\")"],"metadata":{"id":"iyf5fBmWyTbW","executionInfo":{"status":"ok","timestamp":1734816990477,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEXyiVdpyTY0","executionInfo":{"status":"ok","timestamp":1734817060407,"user_tz":-60,"elapsed":69934,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}},"outputId":"51304f21-93b3-4333-9e46-c0f382e02c48"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[*] Séparateur détecté : ';' (défaut : ',')\n","[*] CSV chargé : 26108 lignes, 15 colonnes.\n","[*] Démarrage du clustering HDBSCAN...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[*] Clustering HDBSCAN terminé.\n","[*] Fichier CSV enregistré dans : /content/drive/MyDrive/COLAB_NLP/DATA/transcripts.csv\n","    -> Nouvelle colonne : cluster_video_view_count_video_like_count_video_comment_count_sentiment\n","[*] Script HDBSCAN terminé avec succès.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7_bXum3fyTWM","executionInfo":{"status":"ok","timestamp":1734817060408,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NMLtoV3GyTT1","executionInfo":{"status":"ok","timestamp":1734817060408,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1Y5W1U5syTRu","executionInfo":{"status":"aborted","timestamp":1734812391334,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oFLAaWDpyTPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ri-AgIYEyTMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z5sJC1SByTKP"},"execution_count":null,"outputs":[]}]}