{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlVoc2m6mOeSN0Bm09FaC/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""],"metadata":{"id":"pAyEuBiFSqvM","executionInfo":{"status":"ok","timestamp":1735474134159,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n","import psycopg2\n","\n","def sliding_windows(text, tokenizer, window_size=512, stride=256):\n","    \"\"\"\n","    Génère des sous-textes à partir de 'text' en utilisant une fenêtre\n","    glissante de taille 'window_size', chevauchant de 'stride'.\n","    Le dernier bloc sera ajusté à 'window_size' si le texte est suffisamment long.\n","    Renvoie (chunk_text, start_token_idx, end_token_idx).\n","    \"\"\"\n","    tokens = tokenizer.encode(text, add_special_tokens=False)\n","    n_tokens = len(tokens)\n","\n","    # Si le texte est inférieur à la taille de la fenêtre, ne pas diviser\n","    if n_tokens <= window_size:\n","        yield text, 0, n_tokens\n","        return\n","\n","    i = 0\n","    while i < n_tokens:\n","        # Si le prochain saut dépasse la fin, on ajuste le début du bloc final\n","        if i + window_size >= n_tokens:\n","            i = max(0, n_tokens - window_size)\n","\n","        # On prend un morceau de 'tokens' depuis i jusqu'à i+window_size\n","        chunk_tokens = tokens[i : i + window_size]\n","        if not chunk_tokens:\n","            break\n","\n","        # Redécoder pour récupérer la string\n","        chunk_text = tokenizer.decode(chunk_tokens, skip_special_tokens=True)\n","\n","        # Indices de token effectifs\n","        start_idx = i\n","        end_idx = i + len(chunk_tokens)\n","\n","        yield chunk_text, start_idx, end_idx\n","\n","        # Arrêter si on est à la fin\n","        if i + window_size >= n_tokens:\n","            break\n","\n","        # Avancer de 'stride' (et non pas de window_size)\n","        i += stride\n","\n","def analyze_with_sliding_window(text, sentiment_pipeline, tokenizer, window_size=512, stride=256):\n","    \"\"\"\n","    Applique un pipeline d'analyse de sentiments sur des fenêtres glissantes.\n","\n","    Retourne une liste de dicts :\n","    [\n","        {\n","            \"start_token_idx\": <int>,\n","            \"end_token_idx\": <int>,\n","            \"sentiment\": <résultat du pipeline (liste complète)>\n","        },\n","        ...\n","    ]\n","    \"\"\"\n","    results = []\n","    for chunk_text, start_idx, end_idx in sliding_windows(text, tokenizer, window_size, stride):\n","        # Le pipeline renvoie une liste (ex: [{'label': '4 stars', 'score': 0.997}, ...])\n","        # Ici, on récupère directement TOUT le résultat sans se limiter au premier élément\n","        sentiment_result = sentiment_pipeline(chunk_text)\n","\n","        results.append({\n","            \"start_token_idx\": start_idx,\n","            \"end_token_idx\": end_idx,\n","            \"sentiment\": sentiment_result  # on stocke la liste entière\n","        })\n","    return results"],"metadata":{"id":"FhbvmozI1PND","executionInfo":{"status":"ok","timestamp":1735474357711,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n","import psycopg2\n","from tqdm import tqdm\n","\n","def process_and_store_sentiments(\n","    db_host=\"localhost\",\n","    db_port=5432,\n","    db_name=\"postgres\",\n","    db_user=\"jeremie\",\n","    db_password=\"\",\n","    table_transcript=\"transcript\",\n","    table_sentiment=\"sentiment\",\n","    model_name=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n","    window_size=512,\n","    stride=256\n","):\n","    \"\"\"\n","    Exemple de fonction qui :\n","    1) se connecte à PostgreSQL\n","    2) lit la table 'transcript' (video_id, content)\n","    3) applique l'analyse sliding window\n","    4) stocke dans la table 'sentiment'\n","    \"\"\"\n","\n","    # -- Charger le modèle et le tokenizer --\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","\n","    # -- Créer la pipeline --\n","    sentiment_pipeline = pipeline(\n","        'sentiment-analysis',\n","        model=model,\n","        tokenizer=tokenizer,\n","        truncation=True,  # Sécurité supplémentaire\n","        max_length=512\n","    )\n","\n","    # -- Connexion à la DB (psycopg2) --\n","    conn_string = f\"host={db_host} port={db_port} dbname={db_name} user={db_user} password={db_password}\"\n","    with psycopg2.connect(conn_string) as conn:\n","        with conn.cursor() as cur:\n","            # 1) Récupérer les 20 premières transcriptions seulement (grâce à LIMIT 20)\n","            select_query = f\"\"\"\n","                SELECT transcript_video_id, transcript_content\n","                FROM {table_transcript}\n","            \"\"\"\n","            cur.execute(select_query)\n","            rows = cur.fetchall()\n","\n","            # 2) Pour chaque transcription (avec barre de progression)\n","            for row in tqdm(rows, desc=\"Processing transcripts\"):\n","                video_id, content = row\n","\n","                # Appliquer l'analyse en fenêtre glissante\n","                results = analyze_with_sliding_window(\n","                    text=content,\n","                    sentiment_pipeline=sentiment_pipeline,\n","                    tokenizer=tokenizer,\n","                    window_size=window_size,\n","                    stride=stride\n","                )\n","\n","                # 3) Insérer chaque chunk dans la table \"sentiment\"\n","                insert_query = f\"\"\"\n","                    INSERT INTO {table_sentiment}\n","                    (sentiment_video_id,\n","                     sentiment_start_token_idx,\n","                     sentiment_end_token_idx,\n","                     sentiment_model_name,\n","                     sentiment)\n","                    VALUES (%s, %s, %s, %s, %s)\n","                    ON CONFLICT (sentiment_video_id, sentiment_start_token_idx, sentiment_end_token_idx, sentiment_model_name)\n","                    DO NOTHING\n","                \"\"\"\n","\n","                for res in results:\n","                    start_idx = res[\"start_token_idx\"]\n","                    end_idx = res[\"end_token_idx\"]\n","\n","                    # sentiment_info est une liste\n","                    sentiment_info = res[\"sentiment\"]\n","                    # Convertir en JSON (string) pour l’insérer en base\n","                    sentiment_json = json.dumps(sentiment_info)\n","\n","                    cur.execute(insert_query, (\n","                        video_id,\n","                        start_idx,\n","                        end_idx,\n","                        model_name,\n","                        sentiment_json\n","                    ))\n","\n","            # -- Fin de la boucle, on commit pour valider les insertions --\n","            conn.commit()"],"metadata":{"id":"EdDb4J5G1PKd","executionInfo":{"status":"ok","timestamp":1735474509029,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import json"],"metadata":{"id":"AUTatrb7UeO9","executionInfo":{"status":"ok","timestamp":1735474510807,"user_tz":-60,"elapsed":17,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["process_and_store_sentiments(\n","    db_host=\"localhost\",\n","    db_port=5432,\n","    db_name=\"postgres\",\n","    db_user=\"jeremie\",\n","    db_password=\"\",\n","    table_transcript=\"transcript\",\n","    table_sentiment=\"sentiment\",\n","    model_name=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n","    window_size=512,\n","    stride=256\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YNVidzR1PH7","executionInfo":{"status":"ok","timestamp":1735520953527,"user_tz":-60,"elapsed":46442530,"user":{"displayName":"Jérémie Garrigues","userId":"14912292466158867073"}},"outputId":"d0a433df-bb2b-4de4-c0a1-dce0bfdc8c94"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use mps:0\n","Processing transcripts:   0%|                                                                                                                                     | 0/38473 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (14077 > 512). Running this sequence through the model will result in indexing errors\n","Processing transcripts: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38473/38473 [12:53:54<00:00,  1.21s/it]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"BuQ15MFA1PFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N0hoWf1IPJWP"},"execution_count":null,"outputs":[]}]}